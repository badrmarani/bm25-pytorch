{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Iterable, Sequence\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "def get_device(device_id: int | None = None) -> torch.device:\n",
    "    device_name = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device_name = \"cuda\"\n",
    "        if device_id is not None and 0 <= device_id < torch.cuda.device_count():\n",
    "            device_name = f\"cuda:{device_id}\"\n",
    "    return torch.device(device_name)\n",
    "\n",
    "\n",
    "def generate_batch(data: Sequence[Any], batch_size: int):\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data[i : i + batch_size]\n",
    "        yield batch\n",
    "\n",
    "\n",
    "class BM25:\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer_name_or_path: str | None = None,\n",
    "        device: int | None = None,\n",
    "        k1: float = 1.5,\n",
    "        b: float = 0.75,\n",
    "    ) -> None:\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "\n",
    "        self.device = get_device(device)\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(tokenizer_name_or_path, use_fast=True)\n",
    "        self.tokenizer_fn = lambda s: tokenizer(s, return_tensors=\"pt\", padding=True).input_ids.to(device=device)\n",
    "        self.vocab_size = tokenizer.vocab_size\n",
    "\n",
    "    def index(self, corpus: list[str], batch_size: int = 6) -> torch.Tensor:\n",
    "        x = []\n",
    "        self.total_num_documents = 0\n",
    "        for batch in generate_batch(corpus, min(batch_size, len(corpus))):\n",
    "            ids = self.tokenizer_fn(batch)\n",
    "            num_documents, seq_length = ids.size()\n",
    "\n",
    "            indices = torch.stack((torch.arange(num_documents).unsqueeze(1).expand(-1, seq_length), ids))\n",
    "\n",
    "            _x = torch.sparse_coo_tensor(\n",
    "                indices=indices.reshape(2, -1),\n",
    "                values=(ids > 0).int().flatten(),\n",
    "                size=(num_documents, self.vocab_size),\n",
    "                device=self.device,\n",
    "            )\n",
    "            x.append(_x)\n",
    "            self.total_num_documents += num_documents\n",
    "        self.vs = torch.cat(x).coalesce()\n",
    "        self.document_length = self.vs.sum(dim=1).to_dense()\n",
    "        self.average_document_length = self.document_length.float().mean()\n",
    "        return self.vs\n",
    "\n",
    "    def idf(self, token_ids: torch.Tensor) -> torch.Tensor:\n",
    "        nq = (self.vs.index_select(1, token_ids.flatten()).to_dense() > 0).sum(dim=0).view(token_ids.size())\n",
    "        return torch.where(\n",
    "            nq > 0,\n",
    "            torch.log((self.total_num_documents - nq + 0.5) / (nq + 0.5) + 1),\n",
    "            torch.zeros_like(token_ids),\n",
    "        )\n",
    "\n",
    "    def score(self, queries: str | list[str]) -> torch.Tensor:\n",
    "        token_ids = self.tokenizer_fn(queries)\n",
    "        f = self.vs.index_select(1, token_ids.flatten()).to_dense().view(self.total_num_documents, *token_ids.size())\n",
    "\n",
    "        a = f * self.k1 + 1\n",
    "        b = f + self.k1 * (1 + self.b * (self.document_length.view(-1, 1, 1) - 1) / self.average_document_length)\n",
    "        return (self.idf(token_ids).unsqueeze(0) * a / b).sum(dim=2).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"bad\",\n",
    "    \"A high bad weight in tf-idf is reached by a high term frequency\",\n",
    "    \"(in the given document) and a low document frequency of the term\",\n",
    "    \"in the whole collection of documents; the weights hence tend to filter\",\n",
    "    \"out common terms. Since the ratio inside the idf's log function is always\",\n",
    "    \"greater than or equal bad bad bad bad bad to 1, the value of idf (and tf-idf) is greater than or equal\",\n",
    "    \"to 0. As a term appears in more documents, the ratio inside the logarithm approaches\",\n",
    "    \"1, bringing the idf and tf-idf closer to 0.\",\n",
    "]\n",
    "query = \"common terms\"\n",
    "\n",
    "retriever = BM25(tokenizer_name_or_path=\"bert-base-uncased\")\n",
    "vs = retriever.index(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9445, 1.7918])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.idf(torch.tensor([2919, 2152]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0]),)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(\n",
    "    torch.tensor([0, 2]) == 0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 2152,  102]])"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.tokenizer_fn(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.791759469228055"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "math.log((8 - 1 + 1 / 2) / (1 + 1 / 2) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[0]]),\n",
       "       values=tensor([2919]),\n",
       "       size=(1,), nnz=1, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor([2919]).to_sparse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 0])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(vs.index_select(1, torch.tensor([2919, 2918])).to_dense().squeeze() > 0).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 2919,  102],\n",
       "        [ 101, 7592,  102]])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = retriever.tokenizer_fn([\"bad\", \"hello\"])\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 0, 0, 5, 0, 0], dtype=torch.int32)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs[..., 2919].to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = vs.size(1)\n",
    "token_counts = torch.zeros((8, vocab_size), dtype=ids.dtype)\n",
    "token_counts.scatter_add_(1, ids, retriever.vs.to_dense().to(dtype=ids.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 2919,  102],\n",
       "        [ 101, 7592,  102]])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = retriever.vs.index_select(1, ids.flatten()).to_dense().reshape((8, *ids.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3]],\n",
       "\n",
       "        [[18]],\n",
       "\n",
       "        [[16]],\n",
       "\n",
       "        [[15]],\n",
       "\n",
       "        [[18]],\n",
       "\n",
       "        [[30]],\n",
       "\n",
       "        [[22]],\n",
       "\n",
       "        [[16]]])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.document_length.to_dense().view(-1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.idf(ids).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.2500)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.average_document_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0572, 0.9445, 0.0572],\n",
       "        [0.0572, 0.0000, 0.0572]])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.idf(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0063, 0.7335, 0.4633, 0.4751, 0.4412, 1.0218, 0.4030, 0.4633],\n",
       "        [1.0063, 0.7335, 0.4633, 0.4751, 0.4412, 1.0218, 0.4030, 0.4633]])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.score([\"badr\", \"badr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"A high weight in tf-idf is reached by a high term frequency\",\n",
    "    \"(in the given document) and a low document frequency of the term\",\n",
    "    \"in the whole collection of documents; the weights hence tend to filter\",\n",
    "    \"out common terms. Since the ratio inside the idf's log function is always\",\n",
    "    \"greater than or equal to 1, the value of idf (and tf-idf) is greater than or equal\",\n",
    "    \"to 0. As a term appears in more documents, the ratio inside the logarithm approaches\",\n",
    "    \"1, bringing the idf and tf-idf closer to 0.\",\n",
    "]\n",
    "query = \"common terms\"\n",
    "\n",
    "retriever = BM25(tokenizer_name_or_path=\"bert-base-uncased\")\n",
    "vs = retriever.index(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4446, 1.4804, 1.5180, 2.4571, 1.2105, 1.2888, 1.4804]])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.score(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bm25-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
